{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d77a17-ee4e-4608-9c49-0ba1709bd438",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-07-22T15:11:31.357147Z",
     "iopub.status.busy": "2025-07-22T15:11:31.356363Z",
     "iopub.status.idle": "2025-07-22T15:11:31.360560Z",
     "shell.execute_reply": "2025-07-22T15:11:31.359711Z",
     "shell.execute_reply.started": "2025-07-22T15:11:31.357116Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parâmetros do pipeline\n",
    "input_config_path = 'config.json'\n",
    "input_validacao_path = 'validacao_resultado.json'\n",
    "output_metricas_path = 'metricas_completas.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76fc426c-f958-402b-a9ac-a4c439ce4f81",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-07-22T15:11:31.624659Z",
     "iopub.status.busy": "2025-07-22T15:11:31.624054Z",
     "iopub.status.idle": "2025-07-22T15:11:31.628008Z",
     "shell.execute_reply": "2025-07-22T15:11:31.627207Z",
     "shell.execute_reply.started": "2025-07-22T15:11:31.624628Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c078da-f0d3-4b4d-b9cd-8730b922c601",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-07-22T15:11:32.132771Z",
     "iopub.status.busy": "2025-07-22T15:11:32.132471Z",
     "iopub.status.idle": "2025-07-22T15:11:32.136823Z",
     "shell.execute_reply": "2025-07-22T15:11:32.136333Z",
     "shell.execute_reply.started": "2025-07-22T15:11:32.132750Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Início do cálculo: 2025-07-22 15:11:32.133995\n",
      "Configuração: config.json\n",
      "Validação: validacao_resultado.json\n",
      "Saída: metricas_completas.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Início do cálculo: {datetime.now()}\")\n",
    "print(f\"Configuração: {input_config_path}\")\n",
    "print(f\"Validação: {input_validacao_path}\")\n",
    "print(f\"Saída: {output_metricas_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8d5292-b655-45e3-a1e8-fc62a8dab048",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-07-22T15:11:32.536378Z",
     "iopub.status.busy": "2025-07-22T15:11:32.535743Z",
     "iopub.status.idle": "2025-07-22T15:11:32.692116Z",
     "shell.execute_reply": "2025-07-22T15:11:32.691230Z",
     "shell.execute_reply.started": "2025-07-22T15:11:32.536350Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração carregada: {'bucket_name': 'experimento-lucas-barbosa', 'pasta_raw': 'raw/', 'pasta_processed': 'processed/', 'pasta_archive': 'archive/', 'colunas_obrigatorias': ['id_experimento', 'id_customer', 'grupo', 'uso', 'valor', 'timestamp'], 'grupo_controle': 'GC'}\n",
      "Validação carregada: 0 arquivos válidos\n",
      "Bucket: experimento-lucas-barbosa\n",
      "Grupo controle: GC\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Baixar config.json\n",
    "s3.download_file('experimento-lucas-barbosa', f'config/{input_config_path}', 'config.json')\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"Configuração carregada: {config}\")\n",
    "\n",
    "# Baixar validacao_resultado.json\n",
    "s3.download_file('experimento-lucas-barbosa', f'artifacts/{input_validacao_path}', 'validacao_resultado.json')\n",
    "with open('validacao_resultado.json', 'r') as f:\n",
    "    validacao = json.load(f)\n",
    "\n",
    "print(f\"Validação carregada: {len(validacao.get('arquivos_validos', []))} arquivos válidos\")\n",
    "\n",
    "# Extrair variáveis do config para uso\n",
    "bucket_name = config['bucket_name']\n",
    "pasta_raw = config['pasta_raw']\n",
    "pasta_processed = config['pasta_processed']\n",
    "grupo_controle = config['grupo_controle']\n",
    "colunas_obrigatorias = config.get('colunas_obrigatorias', ['id_experimento', 'id_customer', 'grupo', 'uso', 'valor', 'timestamp'])\n",
    "\n",
    "print(f\"Bucket: {bucket_name}\")\n",
    "print(f\"Grupo controle: {grupo_controle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea7fb32-10cb-4623-99ec-e6c7e769e394",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-07-22T15:11:33.391292Z",
     "iopub.status.busy": "2025-07-22T15:11:33.390989Z",
     "iopub.status.idle": "2025-07-22T15:11:33.405667Z",
     "shell.execute_reply": "2025-07-22T15:11:33.404842Z",
     "shell.execute_reply.started": "2025-07-22T15:11:33.391269Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funções de cálculo de métricas definidas.\n",
      "Funções de cálculo de métricas definidas.\n"
     ]
    }
   ],
   "source": [
    "# --- Funções de Cálculo de Métricas --- \n",
    "\n",
    "def calcular_metricas_basicas(df_grupo: pd.DataFrame, id_experimento: str, grupo: str, arquivo_origem: str) -> list:\n",
    "    \"\"\"Calcula métricas básicas para um grupo específico.\"\"\"\n",
    "    metricas = []\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    total_usuarios = len(df_grupo)\n",
    "\n",
    "    # Taxa de Conversão\n",
    "    conversao = (df_grupo['uso'] > 0).sum() / total_usuarios * 100 if total_usuarios else 0\n",
    "    metricas.append({'id_experimento': id_experimento, 'grupo': grupo, 'metrica': 'taxa_conversao', 'valor': round(conversao, 2), 'timestamp': timestamp, 'arquivo_origem': arquivo_origem})\n",
    "\n",
    "    # Uso Médio\n",
    "    uso_medio = df_grupo['uso'].mean() if total_usuarios else 0\n",
    "    metricas.append({'id_experimento': id_experimento, 'grupo': grupo, 'metrica': 'uso_medio', 'valor': round(uso_medio, 2), 'timestamp': timestamp, 'arquivo_origem': arquivo_origem})\n",
    "\n",
    "    # Valor Médio\n",
    "    valor_medio = df_grupo['valor'].mean() if total_usuarios else 0\n",
    "    metricas.append({'id_experimento': id_experimento, 'grupo': grupo, 'metrica': 'valor_medio', 'valor': round(valor_medio, 2), 'timestamp': timestamp, 'arquivo_origem': arquivo_origem})\n",
    "    \n",
    "    # Número de Usuários Únicos\n",
    "    usuarios_unicos = df_grupo['id_customer'].nunique() if 'id_customer' in df_grupo.columns else total_usuarios\n",
    "    metricas.append({'id_experimento': id_experimento, 'grupo': grupo, 'metrica': 'usuarios_unicos', 'valor': usuarios_unicos, 'timestamp': timestamp, 'arquivo_origem': arquivo_origem})\n",
    "\n",
    "    # --- Adicione novas métricas básicas aqui! --- \n",
    "    # Exemplo: Valor Total\n",
    "    # valor_total = df_grupo['valor'].sum() if total_usuarios else 0\n",
    "    # metricas.append({'id_experimento': id_experimento, 'grupo': grupo, 'metrica': 'valor_total', 'valor': round(valor_total, 2), 'timestamp': timestamp, 'arquivo_origem': arquivo_origem})\n",
    "\n",
    "    return metricas\n",
    "\n",
    "def calcular_lifts(df_metricas_basicas: pd.DataFrame, id_experimento: str, grupo_controle: str, arquivo_origem: str) -> list:\n",
    "    \"\"\"Calcula métricas de lift comparando grupos com o grupo de controle.\"\"\"\n",
    "    lifts = []\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    df_gc = df_metricas_basicas[df_metricas_basicas['grupo'] == grupo_controle]\n",
    "\n",
    "    for metrica_base in ['taxa_conversao', 'uso_medio', 'valor_medio', 'usuarios_unicos']:\n",
    "        base_rows = df_gc[df_gc['metrica'] == metrica_base]\n",
    "        if base_rows.empty:\n",
    "            print(f\" Métrica base '{metrica_base}' não encontrada para o grupo de controle. Pulando lifts.\")\n",
    "            continue\n",
    "        valor_controle = base_rows['valor'].iloc[0]\n",
    "\n",
    "        if valor_controle <= 0:\n",
    "            print(f\" Valor de controle para '{metrica_base}' é zero ou negativo. Pulando lifts.\")\n",
    "            continue\n",
    "\n",
    "        for grupo in df_metricas_basicas['grupo'].unique():\n",
    "            if grupo == grupo_controle: continue\n",
    "\n",
    "            grupo_rows = df_metricas_basicas[(df_metricas_basicas['grupo'] == grupo) & (df_metricas_basicas['metrica'] == metrica_base)]\n",
    "            if grupo_rows.empty:\n",
    "                print(f\" Métrica '{metrica_base}' não encontrada para o grupo '{grupo}'. Pulando lift.\")\n",
    "                continue\n",
    "            valor_grupo = grupo_rows['valor'].iloc[0]\n",
    "\n",
    "            lift_valor = round((valor_grupo - valor_controle) / valor_controle * 100, 2)\n",
    "            lifts.append({'id_experimento': id_experimento, 'grupo': grupo, 'metrica': f'lift_{metrica_base}', 'valor': lift_valor, 'timestamp': timestamp, 'arquivo_origem': arquivo_origem})\n",
    "    \n",
    "    # --- Adicione novas métricas de lift aqui! --- \n",
    "    # Se você adicionou 'valor_total' acima, pode adicionar o lift aqui:\n",
    "    # if 'valor_total' in df_metricas_basicas['metrica'].values:\n",
    "    #     base_total = df_gc[df_gc['metrica'] == 'valor_total']['valor'].iloc[0]\n",
    "    #     if base_total > 0:\n",
    "    #         for grupo in df_metricas_basicas['grupo'].unique():\n",
    "    #             if grupo == grupo_controle: continue\n",
    "    #             val_total = df_metricas_basicas[(df_metricas_basicas['grupo'] == grupo) & (df_metricas_basicas['metrica'] == 'valor_total')]['valor'].iloc[0]\n",
    "    #             lifts.append({'id_experimento': id_experimento, 'grupo': grupo, 'metrica': 'lift_valor_total', 'valor': round((val_total - base_total) / base_total * 100, 2), 'timestamp': timestamp, 'arquivo_origem': arquivo_origem})\n",
    "\n",
    "    return lifts\n",
    "\n",
    "def padronizar_grupo_controle(df: pd.DataFrame, grupo_controle_config: str) -> pd.DataFrame:\n",
    "    \"\"\"Padroniza o nome do grupo de controle no DataFrame para o valor do config.\"\"\"\n",
    "    variacoes_possiveis = {\n",
    "        grupo_controle_config.lower().replace('_', '').replace(' ', ''),\n",
    "        \"gc\", \"grupocontrole\", \"grupo_controle\", \"grupo controle\", \"grupo de controle\"\n",
    "    }\n",
    "    df['grupo'] = df['grupo'].apply(\n",
    "        lambda x: grupo_controle_config if str(x).strip().lower().replace('_', '').replace(' ', '') in variacoes_possiveis else x\n",
    "    )\n",
    "    return df\n",
    "\n",
    "print(\"✅ Funções de cálculo de métricas definidas.\")\n",
    "\n",
    "print(\"Funções de cálculo de métricas definidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d24d111e-923d-4ab0-8ec6-b1e322c3d818",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-07-22T15:11:33.972765Z",
     "iopub.status.busy": "2025-07-22T15:11:33.972478Z",
     "iopub.status.idle": "2025-07-22T15:11:33.982131Z",
     "shell.execute_reply": "2025-07-22T15:11:33.981433Z",
     "shell.execute_reply.started": "2025-07-22T15:11:33.972745Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Processando 0 arquivos válidos\n",
      "⚠️ Nenhum arquivo válido para processar\n"
     ]
    }
   ],
   "source": [
    "# --- Processamento Principal ---\n",
    "arquivos_validos = validacao.get('arquivos_validos', [])\n",
    "print(f\"\\n🔄 Processando {len(arquivos_validos)} arquivos válidos\")\n",
    "\n",
    "if len(arquivos_validos) == 0:\n",
    "    print(\"⚠️ Nenhum arquivo válido para processar\")\n",
    "    df_final = pd.DataFrame(columns=[\n",
    "        'id_experimento', 'grupo', 'metrica', 'valor', 'timestamp', 'arquivo_origem'\n",
    "    ])\n",
    "else:\n",
    "    todas_metricas = []\n",
    "    for arquivo_info in arquivos_validos:\n",
    "        arquivo_key = arquivo_info['key']\n",
    "        nome_arquivo = arquivo_info['nome']\n",
    "        print(f\"\\n📁 Processando {nome_arquivo}...\")\n",
    "        # Ler arquivo do S3 (sem try/except, para que erros de leitura sejam explícitos)\n",
    "        df = pd.read_csv(s3.get_object(Bucket=bucket_name, Key=arquivo_key)['Body'])\n",
    "        # Padronizar o nome do grupo de controle no DataFrame\n",
    "        df = padronizar_grupo_controle(df, grupo_controle)\n",
    "        # Processar cada experimento dentro do arquivo\n",
    "        for id_exp in df['id_experimento'].unique():\n",
    "            df_exp = df[df['id_experimento'] == id_exp]\n",
    "            # Calcular métricas básicas para cada grupo\n",
    "            metricas_basicas_exp = []\n",
    "            for grupo in df_exp['grupo'].unique():\n",
    "                df_grupo = df_exp[df_exp['grupo'] == grupo]\n",
    "                metricas_basicas_exp.extend(calcular_metricas_basicas(df_grupo, id_exp, grupo, nome_arquivo))\n",
    "            df_metricas_basicas_exp = pd.DataFrame(metricas_basicas_exp)\n",
    "            # Calcular lifts\n",
    "            lifts_exp = calcular_lifts(df_metricas_basicas_exp, id_exp, grupo_controle, nome_arquivo)\n",
    "            # Combinar e adicionar à lista geral\n",
    "            todas_metricas.extend(metricas_basicas_exp)\n",
    "            todas_metricas.extend(lifts_exp)\n",
    "            print(f\"  ✓ Experimento {id_exp}: {len(metricas_basicas_exp)} métricas básicas + {len(lifts_exp)} lifts\")\n",
    "    # Combinar todas as métricas em um DataFrame final\n",
    "    if todas_metricas:\n",
    "        df_final = pd.DataFrame(todas_metricas)\n",
    "        print(f\"\\n🎉 Total de métricas calculadas: {len(df_final)}\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Nenhuma métrica foi calculada\")\n",
    "        df_final = pd.DataFrame(columns=[\n",
    "            'id_experimento', 'grupo', 'metrica', 'valor', 'timestamp', 'arquivo_origem'\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c2c50a5-7906-4b04-82cc-9024bddb98b9",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-07-22T15:11:34.740680Z",
     "iopub.status.busy": "2025-07-22T15:11:34.740403Z",
     "iopub.status.idle": "2025-07-22T15:11:34.748571Z",
     "shell.execute_reply": "2025-07-22T15:11:34.747771Z",
     "shell.execute_reply.started": "2025-07-22T15:11:34.740657Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Métricas salvas em metricas_completas.csv\n",
      "\n",
      "⚠️ Nenhuma métrica foi gerada\n"
     ]
    }
   ],
   "source": [
    "# Salvar e mostrar resultados\n",
    "df_final.to_csv(output_metricas_path, index=False)\n",
    "print(f\"\\n💾 Métricas salvas em {output_metricas_path}\")\n",
    "\n",
    "# Mostrar resumo detalhado\n",
    "if len(df_final) > 0:\n",
    "    print(f\"\\n📊 Resumo das métricas calculadas:\")\n",
    "    print(f\"  • Experimentos: {df_final['id_experimento'].nunique()}\")\n",
    "    print(f\"  • Grupos: {df_final['grupo'].nunique()}\")\n",
    "    print(f\"  • Tipos de métrica: {df_final['metrica'].nunique()}\")\n",
    "    print(f\"  • Total de registros: {len(df_final)}\")\n",
    "    \n",
    "    print(f\"\\n📈 Métricas por tipo:\")\n",
    "    for metrica, count in df_final['metrica'].value_counts().items():\n",
    "        print(f\"  • {metrica}: {count} registros\")\n",
    "    \n",
    "    print(f\"\\n🔍 Primeiras 5 linhas:\")\n",
    "    print(df_final.head())\n",
    "else:\n",
    "    print(\"\\n⚠️ Nenhuma métrica foi gerada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa8d01c-b30a-42e6-ab31-88848d593262",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-07-22T15:11:35.407130Z",
     "iopub.status.busy": "2025-07-22T15:11:35.406719Z",
     "iopub.status.idle": "2025-07-22T15:11:35.448166Z",
     "shell.execute_reply": "2025-07-22T15:11:35.447495Z",
     "shell.execute_reply.started": "2025-07-22T15:11:35.407107Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado em s3://experimento-lucas-barbosa/processed/metricas_completas.csv\n"
     ]
    }
   ],
   "source": [
    "# Upload do resultado para S3\n",
    "if pasta_processed:\n",
    "    processed_path = f\"{pasta_processed}{output_metricas_path}\"\n",
    "    s3.upload_file(output_metricas_path, bucket_name, processed_path)\n",
    "    print(f\"Resultado em s3://{bucket_name}/{processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37134ae8-48eb-46df-ac76-220f289639eb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
