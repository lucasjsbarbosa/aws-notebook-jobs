{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78420e6c-025f-4cd3-b83b-88cde1f772b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:56:10.400086Z",
     "iopub.status.busy": "2025-07-17T16:56:10.399513Z",
     "iopub.status.idle": "2025-07-17T16:56:10.992399Z",
     "shell.execute_reply": "2025-07-17T16:56:10.991639Z",
     "shell.execute_reply.started": "2025-07-17T16:56:10.400051Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc74f3e6-9b5a-4e19-ab7c-5c4213332509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:56:10.994302Z",
     "iopub.status.busy": "2025-07-17T16:56:10.993441Z",
     "iopub.status.idle": "2025-07-17T16:56:10.998369Z",
     "shell.execute_reply": "2025-07-17T16:56:10.997510Z",
     "shell.execute_reply.started": "2025-07-17T16:56:10.994266Z"
    }
   },
   "outputs": [],
   "source": [
    "NOME_DO_BUCKET = \"experimento-lucas-barbosa\"  # Troque pelo nome do seu bucket\n",
    "PASTA_RAW = \"raw/\"             # Onde estão os arquivos novos\n",
    "PASTA_PROCESSED = \"processed/\" # Onde vamos salvar as métricas\n",
    "PASTA_ARCHIVE = \"archive/\"     # Onde vamos mover os arquivos já processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9485842b-b4d4-4289-bfa9-be308250aefe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:56:11.001254Z",
     "iopub.status.busy": "2025-07-17T16:56:11.000955Z",
     "iopub.status.idle": "2025-07-17T16:56:11.120113Z",
     "shell.execute_reply": "2025-07-17T16:56:11.119290Z",
     "shell.execute_reply.started": "2025-07-17T16:56:11.001227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Conectado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Conectando ao S3\n",
    "try:\n",
    "    s3 = boto3.client('s3')\n",
    "    print(\"   ✓ Conectado com sucesso!\")\n",
    "except Exception as erro:\n",
    "    print(f\"   ✗ Erro ao conectar: {erro}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920b248e-bf12-4f55-8ae7-3aad7794855b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:56:13.331507Z",
     "iopub.status.busy": "2025-07-17T16:56:13.331106Z",
     "iopub.status.idle": "2025-07-17T16:56:13.338216Z",
     "shell.execute_reply": "2025-07-17T16:56:13.337120Z",
     "shell.execute_reply.started": "2025-07-17T16:56:13.331481Z"
    }
   },
   "outputs": [],
   "source": [
    "def buscar_arquivos_novos():\n",
    "    \"\"\"\n",
    "    Esta função busca arquivos na pasta 'raw' que ainda não foram processados\n",
    "    \"\"\"\n",
    "    arquivos_novos = []\n",
    "    \n",
    "    try:\n",
    "        # Listar todos os arquivos na pasta raw\n",
    "        resposta = s3.list_objects_v2(\n",
    "            Bucket=NOME_DO_BUCKET,\n",
    "            Prefix=PASTA_RAW\n",
    "        )\n",
    "        \n",
    "        # Se não tem nenhum arquivo\n",
    "        if 'Contents' not in resposta:\n",
    "            print(\"   → Nenhum arquivo encontrado na pasta raw/\")\n",
    "            return []\n",
    "        \n",
    "        # Para cada arquivo encontrado\n",
    "        for item in resposta['Contents']:\n",
    "            nome_arquivo = item['Key']\n",
    "            \n",
    "            # Pular se for a própria pasta\n",
    "            if nome_arquivo == PASTA_RAW:\n",
    "                continue\n",
    "                \n",
    "            # Verificar se é um arquivo CSV\n",
    "            if nome_arquivo.endswith('.csv'):\n",
    "                # Extrair apenas o nome do arquivo (sem o caminho)\n",
    "                nome_simples = nome_arquivo.split('/')[-1]\n",
    "                \n",
    "                # Verificar se já foi processado\n",
    "                # (checando se existe um arquivo de métricas correspondente)\n",
    "                nome_metricas = f\"{PASTA_PROCESSED}metricas_{nome_simples}\"\n",
    "                \n",
    "                try:\n",
    "                    # Tentar ver se o arquivo de métricas existe\n",
    "                    s3.head_object(Bucket=NOME_DO_BUCKET, Key=nome_metricas)\n",
    "                    print(f\"   → {nome_simples} já foi processado (pulando)\")\n",
    "                except:\n",
    "                    # Se não existe, é um arquivo novo!\n",
    "                    print(f\"   → {nome_simples} é NOVO! Será processado\")\n",
    "                    arquivos_novos.append(nome_arquivo)\n",
    "        \n",
    "        return arquivos_novos\n",
    "        \n",
    "    except Exception as erro:\n",
    "        print(f\"   ✗ Erro ao buscar arquivos: {erro}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238f7a11-9d17-471e-a63f-134a8da6828b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:56:22.065851Z",
     "iopub.status.busy": "2025-07-17T16:56:22.065373Z",
     "iopub.status.idle": "2025-07-17T16:56:22.178162Z",
     "shell.execute_reply": "2025-07-17T16:56:22.177009Z",
     "shell.execute_reply.started": "2025-07-17T16:56:22.065740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → experimento_teste.csv já foi processado (pulando)\n",
      "   → experimento_teste_2.csv é NOVO! Será processado\n",
      "\n",
      "✓ Encontrados 1 arquivos novos para processar\n"
     ]
    }
   ],
   "source": [
    "# Buscar arquivos\n",
    "arquivos_para_processar = buscar_arquivos_novos()\n",
    "\n",
    "if not arquivos_para_processar:\n",
    "    print(\"\\n✓ Nenhum arquivo novo para processar!\")\n",
    "    exit(0)\n",
    "\n",
    "print(f\"\\n✓ Encontrados {len(arquivos_para_processar)} arquivos novos para processar\")\n",
    "\n",
    "# ============================================\n",
    "# PASSO 3: PROCESSAR CADA ARQUIVO\n",
    "# ============================================\n",
    "\n",
    "def baixar_arquivo_do_s3(caminho_s3):\n",
    "    \"\"\"\n",
    "    Baixa um arquivo do S3 e retorna como DataFrame (tabela)\n",
    "    \"\"\"\n",
    "    print(f\"\\n   Baixando arquivo: {caminho_s3}\")\n",
    "    \n",
    "    try:\n",
    "        # Baixar o arquivo\n",
    "        resposta = s3.get_object(\n",
    "            Bucket=NOME_DO_BUCKET,\n",
    "            Key=caminho_s3\n",
    "        )\n",
    "        \n",
    "        # Converter para DataFrame (tabela)\n",
    "        df = pd.read_csv(resposta['Body'])\n",
    "        print(f\"   ✓ Arquivo baixado: {len(df)} linhas\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as erro:\n",
    "        print(f\"   ✗ Erro ao baixar: {erro}\")\n",
    "        return None\n",
    "\n",
    "def validar_arquivo(df):\n",
    "    \"\"\"\n",
    "    Verifica se o arquivo tem as colunas necessárias\n",
    "    \"\"\"\n",
    "    print(\"\\n   Validando arquivo...\")\n",
    "    \n",
    "    # Colunas obrigatórias\n",
    "    colunas_obrigatorias = ['id_experimento', 'id_customer', 'grupo', 'uso', 'valor', 'timestamp']\n",
    "    \n",
    "    # Verificar cada coluna\n",
    "    colunas_faltando = []\n",
    "    for coluna in colunas_obrigatorias:\n",
    "        if coluna not in df.columns:\n",
    "            colunas_faltando.append(coluna)\n",
    "    \n",
    "    if colunas_faltando:\n",
    "        print(f\"   ✗ Faltam colunas: {colunas_faltando}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"   ✓ Todas as colunas presentes\")\n",
    "    \n",
    "    # Verificar se tem grupo controle\n",
    "    if 'GC' not in df['grupo'].values:\n",
    "        print(\"   ✗ Não tem grupo controle (GC)\")\n",
    "        return False\n",
    "    \n",
    "    print(\"   ✓ Grupo controle encontrado\")\n",
    "    \n",
    "    # Verificar se números são válidos\n",
    "    if df['uso'].min() < 0 or df['valor'].min() < 0:\n",
    "        print(\"   ✗ Valores negativos encontrados\")\n",
    "        return False\n",
    "    \n",
    "    print(\"   ✓ Arquivo válido!\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4a773a-6000-442a-9232-ccf07cb58540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:56:37.883834Z",
     "iopub.status.busy": "2025-07-17T16:56:37.883382Z",
     "iopub.status.idle": "2025-07-17T16:56:37.897671Z",
     "shell.execute_reply": "2025-07-17T16:56:37.895779Z",
     "shell.execute_reply.started": "2025-07-17T16:56:37.883807Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcular_metricas(df):\n",
    "    \"\"\"\n",
    "    Calcula as métricas do experimento\n",
    "    \"\"\"\n",
    "    print(\"\\n   Calculando métricas...\")\n",
    "    \n",
    "    # Pegar o ID do experimento\n",
    "    id_experimento = df['id_experimento'].iloc[0]\n",
    "    \n",
    "    # Lista para guardar as métricas\n",
    "    todas_metricas = []\n",
    "    \n",
    "    # Para cada grupo (GC, TESTE_A, etc)\n",
    "    grupos = df['grupo'].unique()\n",
    "    print(f\"   Grupos encontrados: {list(grupos)}\")\n",
    "    \n",
    "    for grupo in grupos:\n",
    "        # Filtrar dados do grupo\n",
    "        dados_grupo = df[df['grupo'] == grupo]\n",
    "        total_clientes = len(dados_grupo)\n",
    "        \n",
    "        # ===== MÉTRICA 1: TAXA DE CONVERSÃO =====\n",
    "        # Quantos % dos clientes usaram o produto\n",
    "        clientes_que_usaram = len(dados_grupo[dados_grupo['uso'] > 0])\n",
    "        taxa_conversao = (clientes_que_usaram / total_clientes * 100) if total_clientes > 0 else 0\n",
    "        \n",
    "        todas_metricas.append({\n",
    "            'id_experimento': id_experimento,\n",
    "            'grupo': grupo,\n",
    "            'metrica': 'taxa_conversao',\n",
    "            'valor': round(taxa_conversao, 2),\n",
    "            'descricao': f'{clientes_que_usaram} de {total_clientes} clientes converteram'\n",
    "        })\n",
    "        \n",
    "        # ===== MÉTRICA 2: USO MÉDIO =====\n",
    "        # Quantas vezes em média cada cliente usou\n",
    "        uso_medio = dados_grupo['uso'].mean()\n",
    "        \n",
    "        todas_metricas.append({\n",
    "            'id_experimento': id_experimento,\n",
    "            'grupo': grupo,\n",
    "            'metrica': 'uso_medio',\n",
    "            'valor': round(uso_medio, 2),\n",
    "            'descricao': f'Média de {uso_medio:.2f} usos por cliente'\n",
    "        })\n",
    "        \n",
    "        # ===== MÉTRICA 3: VALOR MÉDIO =====\n",
    "        # Quanto em média cada cliente gastou\n",
    "        valor_medio = dados_grupo['valor'].mean()\n",
    "        \n",
    "        todas_metricas.append({\n",
    "            'id_experimento': id_experimento,\n",
    "            'grupo': grupo,\n",
    "            'metrica': 'valor_medio',\n",
    "            'valor': round(valor_medio, 2),\n",
    "            'descricao': f'Média de R$ {valor_medio:.2f} por cliente'\n",
    "        })\n",
    "        \n",
    "        # ===== MÉTRICA 4: TICKET MÉDIO =====\n",
    "        # Quanto gastou em média quem gastou algo\n",
    "        clientes_que_gastaram = dados_grupo[dados_grupo['valor'] > 0]\n",
    "        if len(clientes_que_gastaram) > 0:\n",
    "            ticket_medio = clientes_que_gastaram['valor'].mean()\n",
    "        else:\n",
    "            ticket_medio = 0\n",
    "            \n",
    "        todas_metricas.append({\n",
    "            'id_experimento': id_experimento,\n",
    "            'grupo': grupo,\n",
    "            'metrica': 'ticket_medio',\n",
    "            'valor': round(ticket_medio, 2),\n",
    "            'descricao': f'Ticket médio de R$ {ticket_medio:.2f} (apenas quem gastou)'\n",
    "        })\n",
    "        \n",
    "        print(f\"   ✓ Métricas calculadas para grupo {grupo}\")\n",
    "    \n",
    "    # ===== CALCULAR LIFT (MELHORIA VS CONTROLE) =====\n",
    "    print(\"\\n   Calculando lift vs grupo controle...\")\n",
    "    \n",
    "    # Criar DataFrame com as métricas\n",
    "    df_metricas = pd.DataFrame(todas_metricas)\n",
    "    \n",
    "    # Pegar métricas do grupo controle\n",
    "    metricas_gc = df_metricas[df_metricas['grupo'] == 'GC']\n",
    "    \n",
    "    # Para cada métrica do GC\n",
    "    for _, metrica_gc in metricas_gc.iterrows():\n",
    "        tipo_metrica = metrica_gc['metrica']\n",
    "        valor_gc = metrica_gc['valor']\n",
    "        \n",
    "        # Calcular lift para cada grupo teste\n",
    "        for grupo in grupos:\n",
    "            if grupo != 'GC':\n",
    "                # Pegar valor da métrica para este grupo\n",
    "                valor_grupo = df_metricas[\n",
    "                    (df_metricas['grupo'] == grupo) & \n",
    "                    (df_metricas['metrica'] == tipo_metrica)\n",
    "                ]['valor'].iloc[0]\n",
    "                \n",
    "                # Calcular lift\n",
    "                if valor_gc > 0:\n",
    "                    lift = ((valor_grupo - valor_gc) / valor_gc) * 100\n",
    "                else:\n",
    "                    lift = 0\n",
    "                \n",
    "                # Adicionar métrica de lift\n",
    "                todas_metricas.append({\n",
    "                    'id_experimento': id_experimento,\n",
    "                    'grupo': grupo,\n",
    "                    'metrica': f'lift_{tipo_metrica}',\n",
    "                    'valor': round(lift, 2),\n",
    "                    'descricao': f'Lift de {lift:.2f}% vs GC'\n",
    "                })\n",
    "    \n",
    "    print(f\"   ✓ Total de métricas calculadas: {len(todas_metricas)}\")\n",
    "    \n",
    "    # Retornar DataFrame final\n",
    "    return pd.DataFrame(todas_metricas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a80a10-ca76-4dca-9488-5be31801af63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:56:39.065228Z",
     "iopub.status.busy": "2025-07-17T16:56:39.064469Z",
     "iopub.status.idle": "2025-07-17T16:56:39.071707Z",
     "shell.execute_reply": "2025-07-17T16:56:39.070667Z",
     "shell.execute_reply.started": "2025-07-17T16:56:39.065200Z"
    }
   },
   "outputs": [],
   "source": [
    "def salvar_metricas(df_metricas, nome_arquivo_original):\n",
    "    \"\"\"\n",
    "    Salva as métricas calculadas no S3\n",
    "    \"\"\"\n",
    "    print(\"\\n   Salvando métricas...\")\n",
    "    \n",
    "    # Criar nome do arquivo de métricas\n",
    "    nome_simples = nome_arquivo_original.split('/')[-1]\n",
    "    nome_metricas = f\"{PASTA_PROCESSED}metricas_{nome_simples}\"\n",
    "    \n",
    "    try:\n",
    "        # Salvar em arquivo temporário\n",
    "        arquivo_temp = f\"/tmp/metricas_{nome_simples}\"\n",
    "        df_metricas.to_csv(arquivo_temp, index=False)\n",
    "        \n",
    "        # Upload para S3\n",
    "        s3.upload_file(arquivo_temp, NOME_DO_BUCKET, nome_metricas)\n",
    "        \n",
    "        print(f\"   ✓ Métricas salvas em: {nome_metricas}\")\n",
    "        \n",
    "        # Remover arquivo temporário\n",
    "        os.remove(arquivo_temp)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as erro:\n",
    "        print(f\"   ✗ Erro ao salvar: {erro}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccf2de83-8e86-49f0-8b10-b5f5d3030639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:56:41.904869Z",
     "iopub.status.busy": "2025-07-17T16:56:41.904576Z",
     "iopub.status.idle": "2025-07-17T16:56:41.910340Z",
     "shell.execute_reply": "2025-07-17T16:56:41.909085Z",
     "shell.execute_reply.started": "2025-07-17T16:56:41.904846Z"
    }
   },
   "outputs": [],
   "source": [
    "def arquivar_arquivo_original(nome_arquivo_original):\n",
    "    \"\"\"\n",
    "    Move o arquivo original para a pasta archive\n",
    "    \"\"\"\n",
    "    print(\"\\n   Arquivando arquivo original...\")\n",
    "    \n",
    "    # Criar novo nome com timestamp\n",
    "    nome_simples = nome_arquivo_original.split('/')[-1]\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    nome_arquivo_novo = f\"{PASTA_ARCHIVE}{nome_simples.replace('.csv', '')}_processado_{timestamp}.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Copiar para archive\n",
    "        s3.copy_object(\n",
    "            Bucket=NOME_DO_BUCKET,\n",
    "            CopySource={'Bucket': NOME_DO_BUCKET, 'Key': nome_arquivo_original},\n",
    "            Key=nome_arquivo_novo\n",
    "        )\n",
    "        \n",
    "        # Deletar original\n",
    "        s3.delete_object(\n",
    "            Bucket=NOME_DO_BUCKET,\n",
    "            Key=nome_arquivo_original\n",
    "        )\n",
    "        \n",
    "        print(f\"   ✓ Arquivo movido para: {nome_arquivo_novo}\")\n",
    "        \n",
    "    except Exception as erro:\n",
    "        print(f\"   ✗ Erro ao arquivar: {erro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6edfa34-464b-4ec0-88ce-45e94514ce1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:56:43.771210Z",
     "iopub.status.busy": "2025-07-17T16:56:43.770416Z",
     "iopub.status.idle": "2025-07-17T16:56:43.867992Z",
     "shell.execute_reply": "2025-07-17T16:56:43.867057Z",
     "shell.execute_reply.started": "2025-07-17T16:56:43.771181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROCESSANDO ARQUIVO 1/1: raw/experimento_teste_2.csv\n",
      "==================================================\n",
      "\n",
      "   Baixando arquivo: raw/experimento_teste_2.csv\n",
      "   ✓ Arquivo baixado: 20 linhas\n",
      "\n",
      "   Validando arquivo...\n",
      "   ✗ Faltam colunas: ['id_experimento']\n",
      "   ⚠ Pulando devido a erro na validação\n",
      "\n",
      "==================================================\n",
      "PROCESSAMENTO FINALIZADO!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, arquivo in enumerate(arquivos_para_processar, 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"PROCESSANDO ARQUIVO {i}/{len(arquivos_para_processar)}: {arquivo}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 1. Baixar arquivo\n",
    "    df = baixar_arquivo_do_s3(arquivo)\n",
    "    if df is None:\n",
    "        print(\"   ⚠ Pulando devido a erro no download\")\n",
    "        continue\n",
    "    \n",
    "    # 2. Validar\n",
    "    if not validar_arquivo(df):\n",
    "        print(\"   ⚠ Pulando devido a erro na validação\")\n",
    "        continue\n",
    "    \n",
    "    # 3. Calcular métricas\n",
    "    df_metricas = calcular_metricas(df)\n",
    "    \n",
    "    # 4. Salvar métricas\n",
    "    if salvar_metricas(df_metricas, arquivo):\n",
    "        # 5. Arquivar original (só se salvou com sucesso)\n",
    "        arquivar_arquivo_original(arquivo)\n",
    "        print(\"\\n   ✅ ARQUIVO PROCESSADO COM SUCESSO!\")\n",
    "    else:\n",
    "        print(\"\\n   ❌ ERRO NO PROCESSAMENTO\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESSAMENTO FINALIZADO!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a7202-11b8-43d3-870b-48b5312ad231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
